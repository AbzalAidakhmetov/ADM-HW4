{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import *\n",
    "from collections import *\n",
    "import collections\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recommendation sytem \n",
    "Implementing a recommendation system is critical for businesses and digital platforms that want to thrive in today's competitive environment. These systems use data-driven personalization to tailor content, products, and services to individual user preferences. The latter improves user engagement, satisfaction, retention, and revenue through increased sales and cross-selling opportunities. In this section, you will attempt to implement a recommendation system by identifying similar users' preferences and recommending movies they watch to the study user. \n",
    "\n",
    "To be more specific, you will implement your version of the [**LSH algorithm**](https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/), which will take as input the user's preferred genre of movies, find the most similar users to this user, and recommend the most watched movies by those who are more similar to the user. \n",
    "\n",
    "__Data__: The data you will be working with can be found [here](https://www.kaggle.com/datasets/vodclickstream/netflix-audience-behaviour-uk-movies).\n",
    "\n",
    "Looking at the data, you can see that there is data available for each user for the movies the user <ins>clicked on</ins>. Gather the __title and genre__ of the __maximum top 10 movies__ that each user clicked on regarding the __number of clicks__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/theballer/Desktop/Sapienza Courses/ADM/ADM-HW4-Dataset/vodclickstream_uk_movies_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58773</td>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58774</td>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58775</td>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58776</td>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58777</td>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             datetime  duration  \\\n",
       "0       58773  2017-01-01 01:15:09       0.0   \n",
       "1       58774  2017-01-01 13:56:02       0.0   \n",
       "2       58775  2017-01-01 15:17:47   10530.0   \n",
       "3       58776  2017-01-01 16:04:13      49.0   \n",
       "4       58777  2017-01-01 19:16:37       0.0   \n",
       "\n",
       "                                title  \\\n",
       "0  Angus, Thongs and Perfect Snogging   \n",
       "1        The Curse of Sleeping Beauty   \n",
       "2                   London Has Fallen   \n",
       "3                            Vendetta   \n",
       "4     The SpongeBob SquarePants Movie   \n",
       "\n",
       "                                              genres release_date    movie_id  \\\n",
       "0                             Comedy, Drama, Romance   2008-07-25  26bd5987e8   \n",
       "1                 Fantasy, Horror, Mystery, Thriller   2016-06-02  f26ed2675e   \n",
       "2                                   Action, Thriller   2016-03-04  f77e500e7a   \n",
       "3                                      Action, Drama   2015-06-12  c74aec7673   \n",
       "4  Animation, Action, Adventure, Comedy, Family, ...   2004-11-19  a80d6fc2aa   \n",
       "\n",
       "      user_id  \n",
       "0  1dea19f6fe  \n",
       "1  544dcbc510  \n",
       "2  7cbcc791bf  \n",
       "3  ebf43c36b6  \n",
       "4  a57c992287  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top movies clicked by the users in total.\n",
    "\n",
    "So, here I have grouped by title and genres first and used count method, after I sorted by duration, which is basically sorting by count number, not by the values of duration itself, because I used group by on them all the columns will have the count number, instead of regular numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Mirror: Bandersnatch</td>\n",
       "      <td>Drama, Mystery, Sci-Fi, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bright</td>\n",
       "      <td>Action, Fantasy, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annihilation</td>\n",
       "      <td>Adventure, Drama, Horror, Mystery, Sci-Fi, Thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hot Fuzz</td>\n",
       "      <td>Action, Comedy, Mystery, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Action, Adventure, Comedy, Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bird Box</td>\n",
       "      <td>Drama, Horror, Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FYRE: The Greatest Party That Never Happened</td>\n",
       "      <td>Documentary, Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Big Short</td>\n",
       "      <td>Biography, Comedy, Drama, History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hitman's Bodyguard</td>\n",
       "      <td>Action, Comedy, Crime, Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "0                    Black Mirror: Bandersnatch   \n",
       "1                                        Bright   \n",
       "2                       Avengers: Age of Ultron   \n",
       "3                                  Annihilation   \n",
       "4                                      Hot Fuzz   \n",
       "5                                      Deadpool   \n",
       "6                                      Bird Box   \n",
       "7  FYRE: The Greatest Party That Never Happened   \n",
       "8                                 The Big Short   \n",
       "9                        The Hitman's Bodyguard   \n",
       "\n",
       "                                              genres  \n",
       "0                   Drama, Mystery, Sci-Fi, Thriller  \n",
       "1                          Action, Fantasy, Thriller  \n",
       "2                          Action, Adventure, Sci-Fi  \n",
       "3  Adventure, Drama, Horror, Mystery, Sci-Fi, Thr...  \n",
       "4                  Action, Comedy, Mystery, Thriller  \n",
       "5                  Action, Adventure, Comedy, Sci-Fi  \n",
       "6                              Drama, Horror, Sci-Fi  \n",
       "7                                 Documentary, Music  \n",
       "8                  Biography, Comedy, Drama, History  \n",
       "9                    Action, Comedy, Crime, Thriller  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=['title', 'genres']).count().sort_values(by='duration', ascending=False).reset_index()[['title', 'genres']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Minhash Signatures \n",
    "Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket. \n",
    "\n",
    "__Important note:__ You must write your minhash function from scratch.  You are not permitted to use any already implemented hash functions.  Read the class materials and, if necessary, conduct an internet search.  The description of hash functions in the [book](http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf) may be helpful as a reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58773</td>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58774</td>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58775</td>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58776</td>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58777</td>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             datetime  duration  \\\n",
       "0       58773  2017-01-01 01:15:09       0.0   \n",
       "1       58774  2017-01-01 13:56:02       0.0   \n",
       "2       58775  2017-01-01 15:17:47   10530.0   \n",
       "3       58776  2017-01-01 16:04:13      49.0   \n",
       "4       58777  2017-01-01 19:16:37       0.0   \n",
       "\n",
       "                                title  \\\n",
       "0  Angus, Thongs and Perfect Snogging   \n",
       "1        The Curse of Sleeping Beauty   \n",
       "2                   London Has Fallen   \n",
       "3                            Vendetta   \n",
       "4     The SpongeBob SquarePants Movie   \n",
       "\n",
       "                                              genres release_date    movie_id  \\\n",
       "0                             Comedy, Drama, Romance   2008-07-25  26bd5987e8   \n",
       "1                 Fantasy, Horror, Mystery, Thriller   2016-06-02  f26ed2675e   \n",
       "2                                   Action, Thriller   2016-03-04  f77e500e7a   \n",
       "3                                      Action, Drama   2015-06-12  c74aec7673   \n",
       "4  Animation, Action, Adventure, Comedy, Family, ...   2004-11-19  a80d6fc2aa   \n",
       "\n",
       "      user_id  \n",
       "0  1dea19f6fe  \n",
       "1  544dcbc510  \n",
       "2  7cbcc791bf  \n",
       "3  ebf43c36b6  \n",
       "4  a57c992287  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea for solving \n",
    "\n",
    "First of all, let's create a dataframe with all genres that have been watched by unique users. So, we can use it for further calculations and for creation of a signature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lsh will contain only user_id and genres\n",
    "df_lsh = df.loc[:,['user_id', 'genres']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "#drop potential null values from the description column\n",
    "df_lsh = df_lsh.dropna(subset=['genres'])\n",
    "#uses apply method with list comprehension to tokenize each row and stem each genre\n",
    "df_lsh['genres_clean'] = df_lsh.genres.apply(lambda row: [stemmer.stem(word) for word in nltk.word_tokenize(row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I noticed that there are some redundant words and symbols, which I will take away\n",
    "remove_words = [',', 'avail', 'not']\n",
    "df_lsh.genres_clean = df_lsh.genres_clean.apply(lambda row: [word for word in row if word not in remove_words]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [None, None, None]\n",
       "1                     [None, None, None, None]\n",
       "2                                 [None, None]\n",
       "3                                 [None, None]\n",
       "4         [None, None, None, None, None, None]\n",
       "                          ...                 \n",
       "671731                                  [None]\n",
       "671732          [None, None, None, None, None]\n",
       "671733                      [None, None, None]\n",
       "671734                            [None, None]\n",
       "671735                            [None, None]\n",
       "Name: genres_clean, Length: 671736, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add unique genres to out vocabulary set\n",
    "vocabulary = set()\n",
    "df_lsh.genres_clean.apply(lambda row: [vocabulary.add(word) for word in row]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dea19f6fe</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>[comedi, drama, romanc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544dcbc510</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>[fantasi, horror, mysteri, thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7cbcc791bf</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>[action, thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebf43c36b6</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>[action, drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a57c992287</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>[anim, action, adventur, comedi, famili, fantasi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                             genres  \\\n",
       "0  1dea19f6fe                             Comedy, Drama, Romance   \n",
       "1  544dcbc510                 Fantasy, Horror, Mystery, Thriller   \n",
       "2  7cbcc791bf                                   Action, Thriller   \n",
       "3  ebf43c36b6                                      Action, Drama   \n",
       "4  a57c992287  Animation, Action, Adventure, Comedy, Family, ...   \n",
       "\n",
       "                                        genres_clean  \n",
       "0                            [comedi, drama, romanc]  \n",
       "1               [fantasi, horror, mysteri, thriller]  \n",
       "2                                 [action, thriller]  \n",
       "3                                    [action, drama]  \n",
       "4  [anim, action, adventur, comedi, famili, fantasi]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lsh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice\n",
    "\n",
    "In the above dataframe we already have a list of genres that user watched, but they are not unique, thus, let us use grouby with sum, so the lists of the same users will be added together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lsh = df_lsh.groupby(by='user_id').agg({'genres_clean': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove repeated values from the lists just by converting them to set\n",
    "df_lsh.genres_clean = df_lsh.genres_clean.apply(lambda row: set(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lsh = df_lsh.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert vocabulary and the watched genres by the users again to the list, so we can easily work further\n",
    "vocabulary = list(vocabulary)\n",
    "df_lsh.genres_clean = df_lsh.genres_clean.apply(lambda row: list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>genres_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004e2862</td>\n",
       "      <td>[crime, drama, thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000052a0a0</td>\n",
       "      <td>[comedi, horror, drama, mysteri, fantasi, adve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000090e7c8</td>\n",
       "      <td>[mysteri, thriller, sci-fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000118a755</td>\n",
       "      <td>[horror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000296842d</td>\n",
       "      <td>[mysteri, thriller, sci-fi, drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                       genres_clean\n",
       "0  00004e2862                           [crime, drama, thriller]\n",
       "1  000052a0a0  [comedi, horror, drama, mysteri, fantasi, adve...\n",
       "2  000090e7c8                        [mysteri, thriller, sci-fi]\n",
       "3  000118a755                                           [horror]\n",
       "4  000296842d                 [mysteri, thriller, sci-fi, drama]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the final df_lsh, that has unique user ids with all the genres that was watched by the particular user.\n",
    "df_lsh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the Signature Matrix\n",
    "\n",
    "In order to create signature matrix, first we have to create shingles, the index of which will be hashed for creation of the signature matrix. So, in case of some sentences we could have used shingles of two characters, however, here we have specific information, which are genres. Thus, I have decided to use genres as my shingles. \n",
    "\n",
    "Let's use dictionary comprehension for creation of shingles with unique identifiers, they will serve as the row ids that will be hashed in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingle_dict = {genre: i for i, genre in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comedi': 0,\n",
       " 'drama': 1,\n",
       " 'fantasi': 2,\n",
       " 'adventur': 3,\n",
       " 'film-noir': 4,\n",
       " 'sci-fi': 5,\n",
       " 'reality-tv': 6,\n",
       " 'anim': 7,\n",
       " 'mysteri': 8,\n",
       " 'sport': 9,\n",
       " 'thriller': 10,\n",
       " 'crime': 11,\n",
       " 'music': 12,\n",
       " 'action': 13,\n",
       " 'short': 14,\n",
       " 'documentari': 15,\n",
       " 'horror': 16,\n",
       " 'war': 17,\n",
       " 'western': 18,\n",
       " 'famili': 19,\n",
       " 'talk-show': 20,\n",
       " 'new': 21,\n",
       " 'romanc': 22,\n",
       " 'biographi': 23,\n",
       " 'histori': 24}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingle_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "In order to create a signature matrix, we do not need to use the one hot encoding vectores with the genres that every user has watched and permute them further. This is too time consuming. So, the idea is that we really should avoid matrix with most of the values that are zeros. We only care about the values that are ones. \n",
    "\n",
    "Therefore, we use shingle dict that was created above as the true row ids, then let's say that some particular user is watching thriller, sport and crime. We know their true row ids are 24, 23 and 20 respectively. We will use one has function for all users for creating the one row of the signature matrix, hence, we will hash those values of true row ids and take the minimum output from three values and put it to the signature matrix. \n",
    "\n",
    "Now, as the idea of using hash functions and shingle dict is clear, let's explain my approach. I will use 10 different hash functions to create 10 outputs for some particular user's genre, update the signature matrix and go to the next genre of that user and so on untill I finish with one user. This, then iteratively performed on all other users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(shingle_dict)\n",
    "n_sig = 10\n",
    "# Our hash will be (a*x + b) % N, where a and b are random numbers in range of N\n",
    "# Here params will be a and b for all 10 hash functions\n",
    "params = np.random.randint(N, size=[n_sig,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this hash function, to hash the row ids\n",
    "# The hash function is basically (a*x + b) % N\n",
    "def _permuteRow(row):\n",
    "    return (params@np.array([1, row]))%N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a signature matrix with all values as infinity, we make them infinity, \n",
    "# so they will be changed with the outputs from the hash functions \n",
    "# notice that in our signature matrix, columns are users and the rows are the outputs from the unique\n",
    "# hash functions\n",
    "sig = np.full((n_sig, df_lsh.shape[0]), np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the core in creation of the signature matrix, it will go through our previously created \n",
    "# df_lsh, for each user it will update the values in signature matrix, leaving the minimum one. \n",
    "for j, row in df_lsh.iterrows():\n",
    "    for shingle in row['genres_clean']:\n",
    "        orig_row = shingle_dict[shingle]\n",
    "        curr_col = _permuteRow(orig_row)\n",
    "        sig[:,j] = np.minimum(sig[:,j],curr_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42936/1918318916.py:2: RuntimeWarning: invalid value encountered in cast\n",
      "  sig = sig.astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>161908</th>\n",
       "      <th>161909</th>\n",
       "      <th>161910</th>\n",
       "      <th>161911</th>\n",
       "      <th>161912</th>\n",
       "      <th>161913</th>\n",
       "      <th>161914</th>\n",
       "      <th>161915</th>\n",
       "      <th>161916</th>\n",
       "      <th>161917</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 161918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1       2       3       4       5       6       7       8       \\\n",
       "0       8       1       4       3       4       8       7       4       2   \n",
       "1       5       0      10       5       5       5       0      10       0   \n",
       "2       4       4       5      19       5       0      17       6       7   \n",
       "3      14       0       0       9       0       5      23       0       5   \n",
       "4      10       2       9      13       9       4      16       5       2   \n",
       "5      10       1       3       5       3       1      19       1       1   \n",
       "6      14       0      18       4      14      11      10      13       7   \n",
       "7      12       2       2      12       2       2       7      17       2   \n",
       "8      16       0       2      11       2      16      16       8       4   \n",
       "9      15       0      13       0      13       3       2       3       1   \n",
       "\n",
       "   9       ...  161908  161909  161910  161911  161912  161913  161914  \\\n",
       "0       1  ...       6       1       5       1      13       6       4   \n",
       "1      10  ...       0       0      10       0       5       5       5   \n",
       "2       6  ...       0       4      15       7      14       4       6   \n",
       "3       0  ...       1       0       5       2      19       7       0   \n",
       "4       5  ...       0       5       2       5       8       0      10   \n",
       "5       1  ...       1       1       1       1      15       3      16   \n",
       "6       1  ...       3       1       7       1      19       3      14   \n",
       "7       2  ...       2       2       2       2      12       2      12   \n",
       "8       8  ...       0       7       5      14       6       2       8   \n",
       "9       3  ...       2       3       1       2       5       8      13   \n",
       "\n",
       "   161915  161916  161917  \n",
       "0       0       1       8  \n",
       "1       0      10       5  \n",
       "2       0       5       4  \n",
       "3       1       2      14  \n",
       "4       0       0      18  \n",
       "5       1       1      10  \n",
       "6       3       1      14  \n",
       "7       2       2      12  \n",
       "8       0       2      16  \n",
       "9       3       3      15  \n",
       "\n",
       "[10 rows x 161918 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all the values in signature matrix to integer type\n",
    "sig = sig.astype(int)\n",
    "# Let's visualize the signature matrix\n",
    "pd.DataFrame(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Locality-Sensitive Hashing (LSH)\n",
    "\n",
    "Now that your buckets are ready, it's time to ask a few queries. We will provide you with some user_ids and ask you to recommend at __most five movies__ to the user to watch based on the movies clicked by similar users. \n",
    "\n",
    "To recommend at most five movies given a user_id, use the following procedure: \n",
    "\n",
    "1. Identify the <ins>two most similar</ins> users to this user.\n",
    "2. If these two users have any movies __in common__, recommend those movies based on the total number of clicks by these users.\n",
    "3. If there are __no more common__ movies, try to propose the most clicked movies by the __most similar user first__, followed by the other user. \n",
    "\n",
    "__Note:__ At the end of the process, we expect to see at most five movies recommended to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used two sources from the internet, which were really useful. They can be found [here](https://towardsdatascience.com/locality-sensitive-hashing-how-to-find-similar-items-in-a-large-set-with-precision-d907c52b05fc) and [here](https://www.pinecone.io/learn/series/faiss/locality-sensitive-hashing/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach for creating buckets\n",
    "\n",
    "Basically, the following lines of code below, put similar candidates to the same bucket. This is achieved using defaultdict with set values. We start going through columns which are unique users in some particular band, and our keys in defaultdict are column numbers from the signature matrix. Thus, we try to maximize the number of colissions, is two exactly similar columns are encountered they are certainly put to the same bucket, in out case, buckets are simply sets. Defaultdict is used for the case if there is no any key with that value, it will create one without throwing an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def fastCandidatePairs(sig_mat, b, r):\n",
    "    n, d = sig_mat.shape\n",
    "    \n",
    "    hashbuckets = collections.defaultdict(set)\n",
    "    bands = np.array_split(sig_mat, b, axis=0)\n",
    "    for i, band in enumerate(bands):\n",
    "        for j in range(d):\n",
    "            # The last value made a string to prevent colissions between bands\n",
    "            band_id = tuple(list(band[:,j])+[str(i)])\n",
    "            hashbuckets[band_id].add(j)\n",
    "    bucket_candidates = list()\n",
    "    for bucket in hashbuckets.values():\n",
    "        if len(bucket) > 1:\n",
    "            bucket_candidates.append(bucket)\n",
    "    return bucket_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 161918)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = fastCandidatePairs(sig, b=2, r=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing band `b` and row `r`\n",
    "\n",
    "To choose `b` and `r`, we have to lean to the formula from the theory:\n",
    "\n",
    "The threshold \\( t \\) for the Locality-Sensitive Hashing (LSH) theorem, with respect to bands \\( b \\) and rows \\( r \\), is given by:\n",
    "\n",
    "$$\n",
    "t = (1/b)^{1/r}\n",
    "$$\n",
    "\n",
    "Where b times r  is equal to the total number of hash functions used.\n",
    "In our case, when \\( b = 2 \\) bands and \\( r = 5 \\) rows, the threshold \\( t \\) would be:\n",
    "\n",
    "$$\n",
    "t = (1/2)^{1/5} \\approx 0.8706 \n",
    "$$\n",
    "\n",
    "This value of \\( t \\) determines the similarity threshold for hashing to the same bucket in at least one of the bands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After getting our buckets, we need to some score to evaluate which user is more similar than other one\n",
    "# Here, I am using simple Jaccard Similarity, which is basically intersection over union.\n",
    "def score(target_user_id, current_user_id, df):\n",
    "    current_user = df.genres_clean.iloc[current_user_id]\n",
    "    target_user = df.genres_clean.iloc[target_user_id]\n",
    "    return len(set(target_user).intersection(set(current_user)))/len(set(target_user).union(set(current_user)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(candidate_pairs, query_results, user_ids, df):\n",
    "    # iterate over given user_ids\n",
    "    for user_id in user_ids:\n",
    "        # I need to match user_ids to indecies of my df_lsh, which I used to hash and \n",
    "        # perfrom other operations\n",
    "        target_user_id = df.loc[df.user_id == user_id].index[0]\n",
    "        # declare max_heap for keepint top-2 scores \n",
    "        max_heap = []\n",
    "        # Iterate through buckets \n",
    "        for bucket in candidate_pairs:\n",
    "            # Go further if there is out target user for whom we are looking two most similar candidates\n",
    "            if target_user_id in bucket:\n",
    "\n",
    "                # Iterate through users\n",
    "                for current_user_id in bucket:\n",
    "                    # Check if our user is not a target user, if not go further\n",
    "                    if current_user_id != target_user_id:\n",
    "                        # get a score\n",
    "                        current_score = score(target_user_id, current_user_id, df)\n",
    "                        # push the tuple consisting of current score and user_id\n",
    "                        # check if the (current_score, current_user_id) is not already in the max_heap\n",
    "                        # which could be the case, because we have not only one band\n",
    "                        if (current_score, current_user_id) not in max_heap:\n",
    "                            heapq.heappush(max_heap, (current_score, current_user_id))\n",
    "                        if len(max_heap) > 2:\n",
    "                            # remove the minimum if the length of \n",
    "                            # the heap larger than 2\n",
    "                            heapq.heappop(max_heap)\n",
    "        # put the two most simlar candidates after going through all buckets\n",
    "        # it is important because target users could be in other buckets too!\n",
    "        # and our job is to find two most similar candidates across all buckets\n",
    "        query_results[target_user_id] = max_heap\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for finding two most similar users\n",
    "\n",
    "Below, few lines of the code will go through some dummy user_ids and will recommend movies for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ad08fad2ec'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take some user_ids\n",
    "df.user_id[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = [df.user_id[100], df.user_id[140000], df.user_id[51478]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh_results = query(candidate_pairs, {}, user_ids, df_lsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{109317: [(1.0, 160034), (1.0, 160180)],\n",
       " 89168: [(0.8, 17496), (0.8, 155288)],\n",
       " 121616: [(1.0, 155637), (1.0, 157204)]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsh_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Recommendations\n",
    "\n",
    "After acquiring our results as a dictionary with keys as a target users for whom we are finding similar users and values as two tuples with the score and row id of the corresponding user we have to make recommendations for each user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create an empy dataframe where we will put our recommendations for each user\n",
    "recommendations_df = pd.DataFrame(columns=['user_id', 'recommended_movies'])\n",
    "\n",
    "# Go through each user\n",
    "for user_id in user_ids:\n",
    "    recommended_movies = []\n",
    "\n",
    "    # Identify two most similar users\n",
    "    (_, second), (_, first) = lsh_results[df_lsh.loc[df_lsh.user_id == user_id].index[0]]\n",
    "    \n",
    "    # Let's find the movies that were already watched by the target user,\n",
    "    # to not accidentally reccommend those movies\n",
    "    df_target_movies = set(df.loc[df.user_id == user_id].title)\n",
    "    # DataFrames for the first and second users\n",
    "    df_first = df.loc[df.user_id == df_lsh.user_id.iloc[first]]\n",
    "    df_second = df.loc[df.user_id == df_lsh.user_id.iloc[second]]\n",
    "\n",
    "    # Sets of movies for each user\n",
    "    movies_first = set(df_first.title)\n",
    "    movies_second = set(df_second.title)\n",
    "\n",
    "    # Find common movies\n",
    "    common_movies = movies_first.intersection(movies_second)\n",
    "    common_movies = [movie for movie in common_movies if movie not in df_target_movies]\n",
    "\n",
    "    # Go further if there are some common movies\n",
    "    if common_movies:\n",
    "        # concatenate df_second under df_first\n",
    "        combined_df = pd.concat([df_first, df_second])\n",
    "        # filter by common movies\n",
    "        combined_df = combined_df[combined_df.title.isin(common_movies)]\n",
    "        # count the number of times each title was watched and sort them in descending order\n",
    "        combined_df = combined_df.groupby('title').agg({'user_id': 'count'}).reset_index().sort_values(by='user_id', ascending=False)\n",
    "        # add those movies \n",
    "        recommended_movies.extend(combined_df.title.tolist())\n",
    "    if len(recommended_movies) >= 5:\n",
    "        recommended_movies = recommended_movies[:6]\n",
    "    else:\n",
    "        # Add movies from each user if needed\n",
    "        for df_user in [df_first, df_second]:\n",
    "            if len(recommended_movies) < 5:\n",
    "                top_movies = df_user.groupby('title').agg({'user_id':'count'}).reset_index().sort_values(by='user_id', ascending=False)\n",
    "                for movie in top_movies.title:\n",
    "                    # check some edge cases\n",
    "                    if len(recommended_movies) < 5 and movie not in recommended_movies and movie not in df_target_movies:\n",
    "                        recommended_movies.append(movie)\n",
    "    \n",
    "    new_row = pd.DataFrame({'user_id': [user_id], 'recommended_movies': [recommended_movies]})\n",
    "    recommendations_df = pd.concat([recommendations_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing results\n",
    "\n",
    "Below, we have a dataframe with the recommendation movies for each of the target user. \n",
    "Let's try to analyze our results, and see if the recommendations are legitimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommended_movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad08fad2ec</td>\n",
       "      <td>[The Spy Who Dumped Me, Role Models]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8d438090c0</td>\n",
       "      <td>[The Longest Week, Mudbound, Pride, Raising th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c078c3bb09</td>\n",
       "      <td>[Before I Fall, The Overnight, Here Alone, Lov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                 recommended_movies\n",
       "0  ad08fad2ec               [The Spy Who Dumped Me, Role Models]\n",
       "1  8d438090c0  [The Longest Week, Mudbound, Pride, Raising th...\n",
       "2  c078c3bb09  [Before I Fall, The Overnight, Here Alone, Lov..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134067</th>\n",
       "      <td>192840</td>\n",
       "      <td>2017-07-29 15:42:36</td>\n",
       "      <td>103533.0</td>\n",
       "      <td>The Incredible Jessica James</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>f4f5186800</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134842</th>\n",
       "      <td>193615</td>\n",
       "      <td>2017-07-30 20:28:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Handsome Devil</td>\n",
       "      <td>Comedy, Drama, Sport</td>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>cf85ceead2</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134963</th>\n",
       "      <td>193736</td>\n",
       "      <td>2017-07-30 22:56:56</td>\n",
       "      <td>9784.0</td>\n",
       "      <td>Le Week-End</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2013-10-11</td>\n",
       "      <td>50605a2238</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135488</th>\n",
       "      <td>194261</td>\n",
       "      <td>2017-07-31 01:40:00</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>The Accidental Husband</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>2008-02-29</td>\n",
       "      <td>12d726e81f</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135639</th>\n",
       "      <td>194412</td>\n",
       "      <td>2017-07-31 18:54:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>An Unfinished Life</td>\n",
       "      <td>Drama, Family, Romance</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>fe0a7072f2</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135652</th>\n",
       "      <td>194425</td>\n",
       "      <td>2017-07-31 02:59:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Les Misérables</td>\n",
       "      <td>Drama, History, Musical, Romance, War</td>\n",
       "      <td>2012-12-25</td>\n",
       "      <td>99e99b992b</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135729</th>\n",
       "      <td>194502</td>\n",
       "      <td>2017-07-31 03:09:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chef</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>3ba55497d3</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136047</th>\n",
       "      <td>194820</td>\n",
       "      <td>2017-08-01 15:00:27</td>\n",
       "      <td>11115.0</td>\n",
       "      <td>The Virgin Suicides</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>2000-05-19</td>\n",
       "      <td>ef19c6dbea</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138338</th>\n",
       "      <td>197111</td>\n",
       "      <td>2017-08-04 12:01:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dallas Buyers Club</td>\n",
       "      <td>Biography, Drama</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>f28dd5526d</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140000</th>\n",
       "      <td>198773</td>\n",
       "      <td>2017-08-06 19:02:20</td>\n",
       "      <td>5258.0</td>\n",
       "      <td>Be Somebody</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2016-06-10</td>\n",
       "      <td>6550a34aec</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140167</th>\n",
       "      <td>198940</td>\n",
       "      <td>2017-08-07 15:36:24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trainwreck</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2015-07-17</td>\n",
       "      <td>230728d966</td>\n",
       "      <td>8d438090c0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             datetime  duration  \\\n",
       "134067      192840  2017-07-29 15:42:36  103533.0   \n",
       "134842      193615  2017-07-30 20:28:09       0.0   \n",
       "134963      193736  2017-07-30 22:56:56    9784.0   \n",
       "135488      194261  2017-07-31 01:40:00    4750.0   \n",
       "135639      194412  2017-07-31 18:54:51       0.0   \n",
       "135652      194425  2017-07-31 02:59:10       0.0   \n",
       "135729      194502  2017-07-31 03:09:10       0.0   \n",
       "136047      194820  2017-08-01 15:00:27   11115.0   \n",
       "138338      197111  2017-08-04 12:01:16       0.0   \n",
       "140000      198773  2017-08-06 19:02:20    5258.0   \n",
       "140167      198940  2017-08-07 15:36:24       0.0   \n",
       "\n",
       "                               title                                 genres  \\\n",
       "134067  The Incredible Jessica James                                 Comedy   \n",
       "134842                Handsome Devil                   Comedy, Drama, Sport   \n",
       "134963                   Le Week-End                 Comedy, Drama, Romance   \n",
       "135488        The Accidental Husband                        Comedy, Romance   \n",
       "135639            An Unfinished Life                 Drama, Family, Romance   \n",
       "135652                Les Misérables  Drama, History, Musical, Romance, War   \n",
       "135729                          Chef               Adventure, Comedy, Drama   \n",
       "136047           The Virgin Suicides                         Drama, Romance   \n",
       "138338            Dallas Buyers Club                       Biography, Drama   \n",
       "140000                   Be Somebody                 Comedy, Drama, Romance   \n",
       "140167                    Trainwreck                 Comedy, Drama, Romance   \n",
       "\n",
       "       release_date    movie_id     user_id  \n",
       "134067   2017-07-28  f4f5186800  8d438090c0  \n",
       "134842   2017-06-02  cf85ceead2  8d438090c0  \n",
       "134963   2013-10-11  50605a2238  8d438090c0  \n",
       "135488   2008-02-29  12d726e81f  8d438090c0  \n",
       "135639   2005-09-16  fe0a7072f2  8d438090c0  \n",
       "135652   2012-12-25  99e99b992b  8d438090c0  \n",
       "135729   2014-05-30  3ba55497d3  8d438090c0  \n",
       "136047   2000-05-19  ef19c6dbea  8d438090c0  \n",
       "138338   2013-11-22  f28dd5526d  8d438090c0  \n",
       "140000   2016-06-10  6550a34aec  8d438090c0  \n",
       "140167   2015-07-17  230728d966  8d438090c0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.user_id == \"8d438090c0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of movies recommended for the user 8d438090c0\n",
    "movies = recommendations_df[recommendations_df.user_id == \"8d438090c0\"].recommended_movies.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bring It On: All or Nothing</td>\n",
       "      <td>Comedy, Sport</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mudbound</td>\n",
       "      <td>Drama, War</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mudbound</td>\n",
       "      <td>NOT AVAILABLE</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride</td>\n",
       "      <td>Biography, Comedy, Drama, History, Romance</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raising the Bar</td>\n",
       "      <td>Drama, Family, Sport</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Longest Week</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title                                      genres  \\\n",
       "0  Bring It On: All or Nothing                               Comedy, Sport   \n",
       "1                     Mudbound                                  Drama, War   \n",
       "2                     Mudbound                               NOT AVAILABLE   \n",
       "3                        Pride  Biography, Comedy, Drama, History, Romance   \n",
       "4              Raising the Bar                        Drama, Family, Sport   \n",
       "5             The Longest Week                      Comedy, Drama, Romance   \n",
       "\n",
       "   count  \n",
       "0    186  \n",
       "1    459  \n",
       "2     31  \n",
       "3    187  \n",
       "4    183  \n",
       "5     73  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.title.isin(movies)].groupby(by=['title', 'genres']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "As it can be seen from the dataframes above, the recommended movies make sense, they match on genres and also none of the recommended movies was watched by the target user, which is good. Overall, LSH algorithm was successfully implemented, even though the number of signatures were not so big, because of the limited number of genres. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
